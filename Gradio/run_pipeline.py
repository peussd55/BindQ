import os
import subprocess
from Bio.PDB import PDBParser, Superimposer
import json
import shutil
import numpy as np
import pandas as pd
import gradio as gr
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import tempfile
import ray
import sys
import nglview as nv
import py3Dmol

HOST_WORKSPACE_DIR = os.path.abspath('/home/eps/prj_envs/Gradio')
DOCKER_WORKSPACE_DIR = os.path.abspath('/workspace')

HOST_INPUT_DIR = os.path.join(HOST_WORKSPACE_DIR, 'input')
DOCKER_INPUT_DIR = os.path.join(DOCKER_WORKSPACE_DIR, 'input')

HOST_RFDIFFUSION_OUTPUT_DIR = os.path.join(HOST_WORKSPACE_DIR, 'rfdiffusion_output')
DOCKER_RFDIFFUSION_OUTPUT_DIR = os.path.join(DOCKER_WORKSPACE_DIR, 'rfdiffusion_output')

HOST_PROTEINMPNN_OUTPUT_DIR = os.path.join(HOST_WORKSPACE_DIR, 'proteinmpnn_output')
DOCKER_PROTEINMPNN_OUTPUT_DIR = os.path.join(DOCKER_WORKSPACE_DIR, 'proteinmpnn_output')

if f"{HOST_WORKSPACE_DIR}/af_backprop" not in sys.path:
    sys.path.append(f"{HOST_WORKSPACE_DIR}/af_backprop")

input_files = [f for f in os.listdir(HOST_INPUT_DIR) if f.endswith('.pdb')]
if not input_files:
    print('PDB files does not exists')
    exit(1)
#input_pdb_name = input_files[1].replace('.pdb', '')
try:
    input_pdb_name = input_files[1].replace('.pdb', '')
except IndexError:
    print("Error: Not enough PDB files in the input directory")


def save_uploaded_file(uploaded_file, flag):
    """
    Gradioì—ì„œ ì—…ë¡œë“œí•œ íŒŒì¼ì„ HOST_INPUT_DIRì— ì €ì¥
    :param uploaded_file: gr.File ì»´í¬ë„ŒíŠ¸ë¡œ ì—…ë¡œë“œëœ íŒŒì¼ (ë‹¨ì¼ íŒŒì¼)
    :return: ì €ì¥ ì„±ê³µ ì‹œ ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë©”ì‹œì§€, ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€.
    """
    if not uploaded_file:
        return "íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    file_name = os.path.basename(uploaded_file.name)
    # íŒŒì¼ ì €ì¥ ê²½ë¡œ
    if flag:
        target_path = os.path.join(HOST_RFDIFFUSION_OUTPUT_DIR, file_name)
    else:
        target_path = os.path.join(HOST_INPUT_DIR, file_name)

    try:
        shutil.copy(uploaded_file.name, target_path)
        return f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {target_path}", file_name
    except Exception as e:
        return f"âŒ ì—…ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}"


def process_inputs(name_output, contigs, hotspot_res, iterations, num_designs):
    """ Gradio ì…ë ¥ê°’ì„ JSON í˜•ì‹ì˜ override flagsë¡œ ë³€í™˜í•˜ì—¬ run_inference()ì— ì „ë‹¬ """
    override_flags = {}

    if contigs and not (contigs.startswith('[') and contigs.endswith(']')):
        contigs = '[' + contigs + ']'

    if hotspot_res and not (hotspot_res.startswith('[') and hotspot_res.endswith(']')):
        hotspot_res = '[' + hotspot_res + ']'

    if name_output:
        if name_output.endswith(".pdb"):
            override_flags["inference.input_pdb"] = os.path.join(DOCKER_INPUT_DIR, name_output)
            override_flags["inference.output_prefix"] = os.path.join(
                DOCKER_RFDIFFUSION_OUTPUT_DIR, name_output.replace(".pdb", ""))
        else:
            override_flags["inference.output_prefix"] = os.path.join(
                DOCKER_RFDIFFUSION_OUTPUT_DIR, name_output)
    if contigs:
        override_flags["contigmap.contigs"] = contigs
    if hotspot_res:
        override_flags["ppi.hotspot_res"] = hotspot_res
    if iterations:
        override_flags["diffuser.T"] = iterations
    if num_designs:
        override_flags["inference.num_designs"] = int(num_designs)
    print('son.dumps(override_flags):', json.dumps(override_flags))
    return run_inference_RFdiffusion(json.dumps(override_flags))


def calculate_rmsd(file1, file2):
    parser = PDBParser(QUIET=True)

    structure1 = parser.get_structure("structure1", file1)
    structure2 = parser.get_structure("structure2", file2)

    # CÎ± ì›ìë§Œ ì„ íƒ
    atoms1 = [atom for atom in structure1.get_atoms() if atom.get_name() == "CA"]
    atoms2 = [atom for atom in structure2.get_atoms() if atom.get_name() == "CA"]
    # # ì²« ë²ˆì§¸ ëª¨ë¸ê³¼ ì²« ë²ˆì§¸ ì²´ì¸ ì„ íƒ
    # atoms1 = list(structure1.get_atoms())
    # atoms2 = list(structure2.get_atoms())

    # ë‘ êµ¬ì¡°ì˜ ì›ì ìˆ˜ ë§ì¶”ê¸° (ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ìµœì†Œ ê°œìˆ˜ë§Œí¼ ì‚¬ìš©)
    min_length = min(len(atoms1), len(atoms2))
    atoms1 = atoms1[:min_length]
    atoms2 = atoms2[:min_length]

    # Superimposer ì‚¬ìš©í•˜ì—¬ RMSD ê³„ì‚°
    superimposer = Superimposer()
    superimposer.set_atoms(atoms1, atoms2)
    rmsd = superimposer.rms

    return rmsd


def calc_test(file1, file2):
    import MDAnalysis as mda
    from MDAnalysis.analysis import align
    # PDB íŒŒì¼ ë¡œë“œ
    ref = mda.Universe(file1)  # ê¸°ì¤€ êµ¬ì¡° (ì˜ˆ: ì‹¤í—˜ êµ¬ì¡°)
    mobile = mda.Universe(file2)  # ì´ë™ êµ¬ì¡° (ì˜ˆ: AlphaFold ì˜ˆì¸¡ êµ¬ì¡°)
    # C-alpha ì›ì ì„ íƒ
    ref_calphas = ref.select_atoms("protein and name CA")
    mobile_calphas = mobile.select_atoms("protein and name CA")
    # êµ¬ì¡° ì •ë ¬ (ê¸°ì¤€ êµ¬ì¡°ì— mobile êµ¬ì¡°ë¥¼ ì •ë ¬)
    min_atoms = min(len(mobile_calphas), len(ref_calphas))
    mobile_calphas = mobile_calphas[:min_atoms]
    ref_calphas = ref_calphas[:min_atoms]
    R = align.alignto(mobile_calphas, ref_calphas)
    # RMSD ê³„ì‚° (ì •ë ¬ëœ êµ¬ì¡°ì™€ ê¸°ì¤€ êµ¬ì¡° ê°„ì˜ RMSD)
    rmsd_val = np.sqrt(np.sum((mobile_calphas.positions - ref_calphas.positions)**2) / mobile_calphas.n_atoms)

    return rmsd_val


def extract_plddt_from_pdb(pdb_file):
    parser = PDBParser(QUIET=True)
    structure = parser.get_structure("protein", pdb_file)
    plddt_scores = []
    for atom in structure.get_atoms():
        if atom.get_name() == "CA":  # C-alpha ì›ì ì„ íƒ
            plddt_scores.append(atom.get_bfactor())

    return np.array(plddt_scores)


def calculate_plddt_difference(pdb1, pdb2):
    plddt1 = extract_plddt_from_pdb(pdb1)
    plddt2 = extract_plddt_from_pdb(pdb2)

    # ê¸¸ì´ê°€ ë‹¤ë¥¼ ê²½ìš° ìµœì†Œ ê¸¸ì´ë§Œí¼ ë§ì¶”ê¸°
    min_length = min(len(plddt1), len(plddt2))
    plddt1, plddt2 = plddt1[:min_length], plddt2[:min_length]

    return np.abs(plddt1 - plddt2)  # ì°¨ì´ ê³„ì‚°


def plot_plddt(pdb_file1, pdb_file2):
    plddt1 = extract_plddt_from_pdb(pdb_file1.name)
    plddt2 = extract_plddt_from_pdb(pdb_file2.name)

    # PLDDT Plot
    fig1, ax1 = plt.subplots(figsize=(6, 5))
    ax1.plot(plddt1, color="blue", label="Structure 1")
    ax1.plot(plddt2, color="red", linestyle="dashed", label="Structure 2")
    ax1.set_ylim(0, 100)
    ax1.set_title("PLDDT Score Comparison")
    ax1.set_xlabel("Residue Index")
    ax1.set_ylabel("PLDDT Score")
    ax1.legend()

    # PLDDT Difference Plot
    plddt_diff = calculate_plddt_difference(pdb_file1.name, pdb_file2.name)
    fig2, ax2 = plt.subplots(figsize=(6, 5))
    ax2.plot(plddt_diff, color="purple")
    ax2.set_ylim(0, 50)  # ì°¨ì´ê°’ ë²”ìœ„ ì œí•œ
    ax2.set_title("PLDDT Difference Between Two Structures")
    ax2.set_xlabel("Residue Index")
    ax2.set_ylabel("PLDDT Difference")

    return fig1, fig2


def visualize_pdbs(pdb_file1, pdb_file2):
    # PDB íŒŒì¼ ë¡œë“œ
    with open(pdb_file1.name, "r") as f:
        pdb_data1 = f.read()
    with open(pdb_file2.name, "r") as f:
        pdb_data2 = f.read()

    # HTML ì½”ë“œ ìƒì„± - 3Dmol.js ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ë·°ì–´ ì´ˆê¸°í™” ì½”ë“œ í¬í•¨
    html_code = f"""
    <div style="height: 600px; width: 800px; position: relative;" class='viewer_3Dmoljs' data-href='{pdb_file1.name}' data-backgroundcolor='0xffffff'
        data-style='cartoon' data-ui='true'></div>
    <script src="https://3Dmol.org/build/3Dmol-min.js"></script>
    <script src="https://3Dmol.org/build/3Dmol.ui-min.js"></script>
    <script>
        $(document).ready(function() {{
            let viewer = $3Dmol.createViewer($(".viewer_3Dmoljs"), {{backgroundColor: "white"}});
            viewer.addModel(`{pdb_data1}`, "pdb");
            viewer.setStyle({{}}, {{cartoon: {{color: "blue"}}}});
            viewer.addModel(`{pdb_data2}`, "pdb");
            viewer.setStyle({{"model": 1}}, {{cartoon: {{color: "red"}}}});
            viewer.zoomTo();
            viewer.render();
        }});
    </script>
    """
    return html_code


# input_pdb_path = os.path.join(HOST_INPUT_DIR, input_files[0])
# rfdiffusion_output_pdb = os.path.join(HOST_RFDIFFUSION_OUTPUT_DIR, f'rf_{input_pdb_name}')

# # Run RFdiffusion Container
# print(f'Run RFdiffusion Container - {input_pdb_path}')
# subprocess.run([
#     'docker', 'run', '--rm', '-it', '--gpus', 'all',
#     '-v', f'{HOST_WORKSPACE_DIR}:{DOCKER_WORKSPACE_DIR}', 'rfdiffusion:latest',
#     'python', 'scripts/run_inference.py', f'inference.output_prefix={DOCKER_RFDIFFUSION_OUTPUT_DIR}/{input_pdb_name}', 'inference.model_directory_path=models/',
#     f'inference.input_pdb={DOCKER_INPUT_DIR}/{input_files[0]}', 'inference.num_designs=1', 'contigmap.contigs=[10-40/A163-181/10-40]'
# ])

# # Results Rfdiffusion
# rfd_out_files = [f for f in os.listdir(HOST_RFDIFFUSION_OUTPUT_DIR) if f.endswith('.pdb')]
# if not rfd_out_files:
#     print('âŒ RFdiffusion output PDB files does not exists')
#     exit(1)


def run_inference_RFdiffusion(override_flags_json: str) -> str:
    """
    Gradioë¥¼ í†µí•´ ì…ë ¥ë°›ì€ JSON í˜•ì‹ì˜ flag overrideë¥¼ íŒŒì‹±í•˜ì—¬,
    ê¸°ë³¸ base.yaml ì„¤ì •ì€ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ì‚¬ìš©í•˜ê³ ,
    ì…ë ¥ë°›ì€ ê°’ë§Œ command line ì¸ìë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
    """
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ override ê°’ì´ ìˆì„ ê²½ìš° íŒŒì‹± (ì—†ìœ¼ë©´ ë¹ˆ dict)
    override_flags = {}
    if override_flags_json.strip():
        try:
            override_flags = json.loads(override_flags_json)
            if not isinstance(override_flags, dict):
                return "JSON ì…ë ¥ì€ key-value ìŒì˜ ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤."
        except Exception as e:
            return f"JSON íŒŒì‹± ì—ëŸ¬: {e}"
    
    ### ì¶”ê°€ë¨ ###
    print("override_flags:", override_flags)
    print("numìˆ˜:", override_flags["inference.num_designs"])
    print("idëª…:", (override_flags["inference.input_pdb"]).split('/')[-1].split('.')[0])
    num_desgin = override_flags["inference.num_designs"]
    name_output = (override_flags["inference.input_pdb"]).split('/')[-1].split('.')[0]
    contigs = ""
    hotspots = ""
    if "contigmap.contigs" in override_flags:
        contigs = override_flags["contigmap.contigs"]
    if "ppi.hotspot_res" in override_flags:
        hotspots = override_flags["ppi.hotspot_res"]

    # override flagë“¤ì„ "key=value" í˜•íƒœì˜ ë¬¸ìì—´ë¡œ ë³€í™˜
    flag_args = [f"{key}={value}" for key, value in override_flags.items()]



    # Docker run ëª…ë ¹ì–´ êµ¬ì„±.
    # ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ëŠ” base.yaml íŒŒì¼ì´ ìˆì–´ ê¸°ë³¸ ì„¤ì •ì„ ë¡œë“œí•˜ë¯€ë¡œ,
    # ì¶”ê°€ë¡œ ì „ë‹¬ë˜ëŠ” ì¸ìë§Œ override ë©ë‹ˆë‹¤.
    docker_cmd = [
        'docker', 'run', '--rm', '-it', '--gpus', 'all',
        #'--network', 'host', # í˜¸ìŠ¤íŠ¸ ë„¤íŠ¸ì›Œí¬ ëª¨ë“œ ì‚¬ìš©
        '-v', f'{HOST_WORKSPACE_DIR}:{DOCKER_WORKSPACE_DIR}',
        'rfdiffusion:latest',
        'python', 'scripts/run_inference.py',
    ] + flag_args

    print("ì‹¤í–‰í•  ëª…ë ¹ì–´:", " ".join(docker_cmd))
    try:
        subprocess.run(docker_cmd, check=True)

        ### ì¶”ê°€ë¨ ###
        from function import render_pdbs_by_prefix
        return render_pdbs_by_prefix(name_output, num_desgin, contigs, hotspots) 
        
    except subprocess.CalledProcessError as e:
        return f"Error: {e}"

    #return "ì‹¤í–‰ ì™„ë£Œ"

# # ProteinMPNN Input
# proteinmpnn_input_pdb_name = rfd_out_files[0].replace('.pdb', '')
# proteinmpnn_input_pdb_path = os.path.join(HOST_RFDIFFUSION_OUTPUT_DIR, f'{rfd_out_files[0]}')

# # Run ProteinMPNN Container
# print(f"ğŸš€ ProteinMPNN ì‹¤í–‰: ì…ë ¥ íŒŒì¼ - {proteinmpnn_input_pdb_name}")
# subprocess.run([
#     'docker', 'run', '--rm', '-it', '--gpus', 'all',
#     "-v", f"{HOST_WORKSPACE_DIR}:{DOCKER_WORKSPACE_DIR}",
#     'protein_mpnn:latest',
#     "python", "protein_mpnn_run.py",
#     '--pdb_path', f'{DOCKER_RFDIFFUSION_OUTPUT_DIR}/{rfd_out_files[0]}',
#     '--out_folder', f'{DOCKER_PROTEINMPNN_OUTPUT_DIR}',
#     '--num_seq_per_target', '5',
#     '--batch_size', '1',
#     '--seed', '32'
# ])
# # Results ProteinMPNN
# proteinmpnn_output = [f for f in os.listdir(f'{HOST_PROTEINMPNN_OUTPUT_DIR}/seqs') if f.endswith('.fa')]
# if not proteinmpnn_output:
#     print("âŒ ProteinMPNN ì‹¤í–‰ ì‹¤íŒ¨: FASTA ì¶œë ¥ ì—†ìŒ.")
#     exit(1)

# print("âœ… All Process Complete!")


def run_inference_ProteinMPNN(target_file_1,
                              target_file_2,
                              name_output,
                              num_seq_per_target,
                              sampling_temp,
                              model_name,
                              backbone_noise
                              ):

    # if designed_chain == "":
    #     designed_chain_list = []
    # else:
    #     designed_chain_list = re.sub("[^A-Za-z]+", ",", designed_chain).split(",")

    # if fixed_chain == "":
    #     fixed_chain_list = []
    # else:
    #     fixed_chain_list = re.sub("[^A-Za-z]+", ",", fixed_chain).split(",")

    # chain_list = list(set(designed_chain_list + fixed_chain_list))

    docker_cmd = [
        'docker', 'run', '--rm', '-it', '--gpus', 'all',
        '-v', f'{HOST_WORKSPACE_DIR}:{DOCKER_WORKSPACE_DIR}',
        'protein_mpnn:latest'
    ]

    # # protein_mpnn_run.py ì‹¤í–‰
    docker_cmd.append(
        f'python protein_mpnn_run.py '
        f'--pdb_path {DOCKER_RFDIFFUSION_OUTPUT_DIR}/{name_output} '
        f'--out_folder {DOCKER_PROTEINMPNN_OUTPUT_DIR} '
        f'--seed 32 --batch_size 1 --save_probs 1 '
    )
    
    if num_seq_per_target:
        docker_cmd.append(f'--num_seq_per_target {num_seq_per_target} ')
    # if sampling_temp:
    #     docker_cmd.append(f'--sampling_temp {sampling_temp} ')
    # if model_name:
    #     _, model_name = model_name.split("â€”")
    #     docker_cmd.append(f'--model_name {model_name} ')
    # if backbone_noise:
    #     docker_cmd.append(f'--backbone_noise {backbone_noise} ')

    # try:
    #     subprocess.run(" ".join(docker_cmd), shell=True, check=True)
    # except subprocess.CalledProcessError as e:
    #     return f"Docker ì‹¤í–‰ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}"

    alphabet = "ACDEFGHIKLMNPQRSTVWYX"

    name_output = name_output.replace('.pdb', '')
    data = np.load(f'{HOST_PROTEINMPNN_OUTPUT_DIR}/probs/{name_output}.npz')
    all_log_probs = data['log_probs']
    all_probs = data['probs']
    np.savetxt(
        f'{HOST_PROTEINMPNN_OUTPUT_DIR}/probs/all_log_probs_{name_output}.csv',
        np.exp(all_log_probs).mean(0).T,
        delimiter=','
    )
    np.savetxt(
        f'{HOST_PROTEINMPNN_OUTPUT_DIR}/probs/all_probs_{name_output}.csv',
        np.exp(all_probs).mean(0).T,
        delimiter=','
    )

    fig = px.imshow(
        np.exp(all_log_probs).mean(0).T,
        labels=dict(x="positions", y="amino acids", color="probability"),
        y=list(alphabet),
        template="simple_white",
    )
    fig.update_xaxes(side="top")

    fig_tadjusted = px.imshow(
        all_probs.mean(0).T,
        labels=dict(x="positions", y="amino acids", color="probability"),
        y=list(alphabet),
        template="simple_white",
    )
    # rmsd_out = calculate_rmsd(target_file_1, target_file_2)
    rmsd_out = calculate_rmsd(target_file_1, target_file_2)
    fig1, fig2 = plot_plddt(target_file_1, target_file_2)
    vis_out = visualize_pdbs(target_file_1, target_file_2)
    
    rmsd_out = rmsd_out if rmsd_out is not None else "No Data"
    fig1 = fig1 if fig1 is not None else gr.Plot()
    fig2 = fig2 if fig2 is not None else gr.Plot()
    vis_out = vis_out if vis_out is not None else "No Visualization"
    fig = fig if fig is not None else gr.Plot()
    fig_tadjusted = fig_tadjusted if fig_tadjusted is not None else gr.Plot()
    
    return (
        rmsd_out,
        fig1,
        fig2,
        vis_out,
        '',
        fig,
        fig_tadjusted,
        gr.File(
            value=f'{HOST_PROTEINMPNN_OUTPUT_DIR}/probs/all_log_probs_{name_output}.csv',
            visible=True
        ),
        gr.File(
            value=f'{HOST_PROTEINMPNN_OUTPUT_DIR}/probs/all_probs_{name_output}.csv',
            visible=True
        )
    )
