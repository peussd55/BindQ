import os
import subprocess
import yaml
import json
import shutil

HOST_WORKSPACE_DIR = os.path.abspath('/mnt/c/Users/user/Desktop/FinalProject/Gradio')
DOCKER_WORKSPACE_DIR = os.path.abspath('/workspace')

HOST_INPUT_DIR = os.path.join(HOST_WORKSPACE_DIR, 'input')
DOCKER_INPUT_DIR = os.path.join(DOCKER_WORKSPACE_DIR, 'input')

HOST_RFDIFFUSION_OUTPUT_DIR = os.path.join(HOST_WORKSPACE_DIR, 'rfdiffusion_output')
DOCKER_RFDIFFUSION_OUTPUT_DIR = os.path.join(DOCKER_WORKSPACE_DIR, 'rfdiffusion_output')

HOST_PROTEINMPNN_OUTPUT_DIR = os.path.join(HOST_WORKSPACE_DIR, 'proteinmpnn_output')
DOCKER_PROTEINMPNN_OUTPUT_DIR = os.path.join(DOCKER_WORKSPACE_DIR, 'proteinmpnn_output')

input_files = [f for f in os.listdir(HOST_INPUT_DIR) if f.endswith('.pdb')]
if not input_files:
    print('PDB files does not exists')
    exit(1)
input_pdb_name = input_files[1].replace('.pdb', '')


def save_uploaded_file(uploaded_file):
    """
    Gradioì—ì„œ ì—…ë¡œë“œí•œ íŒŒì¼ì„ HOST_INPUT_DIRì— ì €ì¥
    :param uploaded_file: gr.File ì»´í¬ë„ŒíŠ¸ë¡œ ì—…ë¡œë“œëœ íŒŒì¼ (ë‹¨ì¼ íŒŒì¼)
    :return: ì €ì¥ ì„±ê³µ ì‹œ ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë©”ì‹œì§€, ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€.
    """
    if not uploaded_file:
        return "íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    file_name = os.path.basename(uploaded_file.name)
    # íŒŒì¼ ì €ì¥ ê²½ë¡œ
    target_path = os.path.join(HOST_INPUT_DIR, file_name)

    try:
        shutil.copy(uploaded_file.name, target_path)
        return f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {target_path}", file_name
    except Exception as e:
        return f"âŒ ì—…ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}"


def process_inputs(name_output, contigs, hotspot_res, iterations, num_designs):
    """ Gradio ì…ë ¥ê°’ì„ JSON í˜•ì‹ì˜ override flagsë¡œ ë³€í™˜í•˜ì—¬ run_inference()ì— ì „ë‹¬ """
    override_flags = {}

    if name_output:
        if name_output.endswith(".pdb"):
            override_flags["inference.input_pdb"] = os.path.join(DOCKER_INPUT_DIR, name_output)
            override_flags["inference.output_prefix"] = os.path.join(
                DOCKER_RFDIFFUSION_OUTPUT_DIR, name_output.replace(".pdb", ""))
        else:
            override_flags["inference.output_prefix"] = os.path.join(
                DOCKER_RFDIFFUSION_OUTPUT_DIR, name_output)
    if contigs:
        override_flags["contigmap.contigs"] = contigs
    if hotspot_res:
        override_flags["ppi.hotspot_res"] = hotspot_res
    if iterations:
        override_flags["diffuser.T"] = iterations
    if num_designs:
        override_flags["inference.num_designs"] = int(num_designs)

    return run_inference_RFdiffusion(json.dumps(override_flags))


# input_pdb_path = os.path.join(HOST_INPUT_DIR, input_files[0])
# rfdiffusion_output_pdb = os.path.join(HOST_RFDIFFUSION_OUTPUT_DIR, f'rf_{input_pdb_name}')

# # Run RFdiffusion Container
# print(f'Run RFdiffusion Container - {input_pdb_path}')
# subprocess.run([
#     'docker', 'run', '--rm', '-it', '--gpus', 'all',
#     '-v', f'{HOST_WORKSPACE_DIR}:{DOCKER_WORKSPACE_DIR}', 'rfdiffusion:latest',
#     'python', 'scripts/run_inference.py', f'inference.output_prefix={DOCKER_RFDIFFUSION_OUTPUT_DIR}/{input_pdb_name}', 'inference.model_directory_path=models/',
#     f'inference.input_pdb={DOCKER_INPUT_DIR}/{input_files[0]}', 'inference.num_designs=1', 'contigmap.contigs=[10-40/A163-181/10-40]'
# ])

# # Results Rfdiffusion
# rfd_out_files = [f for f in os.listdir(HOST_RFDIFFUSION_OUTPUT_DIR) if f.endswith('.pdb')]
# if not rfd_out_files:
#     print('âŒ RFdiffusion output PDB files does not exists')
#     exit(1)
def run_inference_RFdiffusion(override_flags_json: str) -> str:
    """
    Gradioë¥¼ í†µí•´ ì…ë ¥ë°›ì€ JSON í˜•ì‹ì˜ flag overrideë¥¼ íŒŒì‹±í•˜ì—¬,
    ê¸°ë³¸ base.yaml ì„¤ì •ì€ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ì‚¬ìš©í•˜ê³ ,
    ì…ë ¥ë°›ì€ ê°’ë§Œ command line ì¸ìë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
    """
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ override ê°’ì´ ìˆì„ ê²½ìš° íŒŒì‹± (ì—†ìœ¼ë©´ ë¹ˆ dict)
    override_flags = {}
    if override_flags_json.strip():
        try:
            override_flags = json.loads(override_flags_json)
            if not isinstance(override_flags, dict):
                return "JSON ì…ë ¥ì€ key-value ìŒì˜ ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤."
        except Exception as e:
            return f"JSON íŒŒì‹± ì—ëŸ¬: {e}"

    # override flagë“¤ì„ "key=value" í˜•íƒœì˜ ë¬¸ìì—´ë¡œ ë³€í™˜
    flag_args = [f"{key}={value}" for key, value in override_flags.items()]

    # Docker run ëª…ë ¹ì–´ êµ¬ì„±.
    # ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ëŠ” base.yaml íŒŒì¼ì´ ìˆì–´ ê¸°ë³¸ ì„¤ì •ì„ ë¡œë“œí•˜ë¯€ë¡œ,
    # ì¶”ê°€ë¡œ ì „ë‹¬ë˜ëŠ” ì¸ìë§Œ override ë©ë‹ˆë‹¤.
    docker_cmd = [
        'docker', 'run', '--rm', '-it', '--gpus', 'all',
        '-v', f'{HOST_WORKSPACE_DIR}:{DOCKER_WORKSPACE_DIR}',
        'rfdiffusion:latest',
        'python', 'scripts/run_inference.py',
    ] + flag_args

    print("ì‹¤í–‰í•  ëª…ë ¹ì–´:", " ".join(docker_cmd))
    try:
        subprocess.run(docker_cmd, check=True)
    except subprocess.CalledProcessError as e:
        return f"Error: {e}"

    return "ì‹¤í–‰ ì™„ë£Œ"

# # ProteinMPNN Input
# proteinmpnn_input_pdb_name = rfd_out_files[0].replace('.pdb', '')
# proteinmpnn_input_pdb_path = os.path.join(HOST_RFDIFFUSION_OUTPUT_DIR, f'{rfd_out_files[0]}')

# # Run ProteinMPNN Container
# print(f"ğŸš€ ProteinMPNN ì‹¤í–‰: ì…ë ¥ íŒŒì¼ - {proteinmpnn_input_pdb_name}")
# subprocess.run([
#     'docker', 'run', '--rm', '-it', '--gpus', 'all',
#     "-v", f"{HOST_WORKSPACE_DIR}:{DOCKER_WORKSPACE_DIR}",
#     'protein_mpnn:latest',
#     "python", "protein_mpnn_run.py",
#     '--pdb_path', f'{DOCKER_RFDIFFUSION_OUTPUT_DIR}/{rfd_out_files[0]}',
#     '--out_folder', f'{DOCKER_PROTEINMPNN_OUTPUT_DIR}',
#     '--num_seq_per_target', '5',
#     '--batch_size', '1',
#     '--seed', '32'
# ])
# # Results ProteinMPNN
# proteinmpnn_output = [f for f in os.listdir(f'{HOST_PROTEINMPNN_OUTPUT_DIR}/seqs') if f.endswith('.fa')]
# if not proteinmpnn_output:
#     print("âŒ ProteinMPNN ì‹¤í–‰ ì‹¤íŒ¨: FASTA ì¶œë ¥ ì—†ìŒ.")
#     exit(1)

# print("âœ… All Process Complete!")


def run_inference_ProteinMPNN(num_seq_per_target, sampling_temp, model_name, backbone_noise):

    docker_cmd = [
        'docker', 'run', '--rm', '-it', '--gpus', 'all',
        '-v', f'{HOST_WORKSPACE_DIR}:{DOCKER_WORKSPACE_DIR}',
        'protein_mpnn:latest',
        'python', 'protein_mpnn_run.py',
        '--out_folder', f'{DOCKER_PROTEINMPNN_OUTPUT_DIR}',
        '--seed', '32',
        '--batch_size', '1'
    ]

    if num_seq_per_target:
        docker_cmd.extend(["--num_seq_per_target", str(num_seq_per_target)])
    if sampling_temp:
        docker_cmd.extend(["--sampling_temp", sampling_temp])
    if model_name:
        docker_cmd.extend(["--model_name", model_name])
    if backbone_noise:
        docker_cmd.extend(["--backbone_noise", backbone_noise])

    try:
        subprocess.run(docker_cmd, check=True)
    except subprocess.CalledProcessError as e:
        return f"Docker ì‹¤í–‰ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}"
    return
